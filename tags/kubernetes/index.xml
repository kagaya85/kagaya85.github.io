<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes on かがやの部屋</title><link>https://blog.kagaya.fun/tags/kubernetes/</link><description>Recent content in Kubernetes on かがやの部屋</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sun, 20 Apr 2025 23:00:00 +0800</lastBuildDate><atom:link href="https://blog.kagaya.fun/tags/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>为什么你需要Server-Side Apply</title><link>https://blog.kagaya.fun/p/2025/server-side-apply/</link><pubDate>Sun, 20 Apr 2025 23:00:00 +0800</pubDate><guid>https://blog.kagaya.fun/p/2025/server-side-apply/</guid><description>&lt;img src="https://blog.kagaya.fun/p/2025/server-side-apply/cover.jpg" alt="Featured image of post 为什么你需要Server-Side Apply" />&lt;h2 id="介绍">介绍
&lt;/h2>&lt;p>&lt;strong>服务器端应用&lt;/strong>（Server-side Apply, SSA）是 Kubernetes 中用于管理资源配置的一种机制&lt;/p>
&lt;p>它将配置应用的逻辑从客户端（如 kubectl）移到 API 服务器，从而更好地处理多个用户或工具同时管理同一资源时的冲突。&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>一句话总结：合理使用 SSA 可以提高并发更新时的成功率，同时通过字段所有权避免意外的字段覆盖&lt;/strong>&lt;/p>&lt;/blockquote>
&lt;h2 id="解决什么问题">解决什么问题？
&lt;/h2>&lt;ul>
&lt;li>不同的controler/client更新同一个资源时的冲突问题&lt;/li>
&lt;li>如果更新不同的字段，后尝试更新的用户需要重试拉取最新的资源再尝试更新&lt;/li>
&lt;li>使用SSA后，可以由服务器判断是否更新成功而不是返回冲突&lt;/li>
&lt;/ul>
&lt;h2 id="版本支持情况">版本支持情况
&lt;/h2>&lt;p>Kubernetes 1.13 引入，1.18 Beta 增加 managerFileds 支持，1.22 GA
实现方式
通过对象元数据中的 managedFields 字段跟踪哪个管理器（比如 kubectl 或某个控制器）拥有哪个字段。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">&lt;span class="nt">metadata&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">  &lt;/span>&lt;span class="nt">managedFields&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">  &lt;/span>- &lt;span class="nt">manager&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">kubectl&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">    &lt;/span>&lt;span class="nt">operation&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="l">Apply&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">    &lt;/span>&lt;span class="l">time: &amp;#34;2025-03-23T23:00:00Z&amp;#34;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">    &lt;/span>&lt;span class="nt">fieldsV1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">      &lt;/span>&lt;span class="nt">f:spec&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">        &lt;/span>&lt;span class="nt">f:replicas&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w"> &lt;/span>{}&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>当发送期望的配置时，服务器会比较当前状态，检查是否有冲突，并根据字段所有权应用更改。如果检测到冲突，服务器可能会拒绝更改或需要手动解决。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>每个 Kubernetes 对象在元数据中包含一个 managedFields 数组，每个条目记录了管理该字段的管理器（manager）信息，包括：&lt;/p>
&lt;ul>
&lt;li>manager：管理器的名称（如 &amp;ldquo;kubectl&amp;rdquo; 或 &amp;ldquo;some-controller&amp;rdquo;）。&lt;/li>
&lt;li>operation：操作类型（如 &amp;ldquo;Apply&amp;rdquo;）。&lt;/li>
&lt;li>time：最后更新时间。&lt;/li>
&lt;li>fieldsV1：一个字段列表，描述该管理器拥有的具体字段。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>当用户或控制器通过 SSA 应用配置时，客户端发送完整的期望配置到 API 服务器，服务器会：&lt;/p>
&lt;ol>
&lt;li>比较当前状态与期望状态，计算差异。&lt;/li>
&lt;li>检查 managedFields，确定每个字段的当前所有者。&lt;/li>
&lt;li>如果检测到冲突（即另一个管理器已更改某个字段），服务器会拒绝更改或根据策略处理（例如返回冲突错误）。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h2 id="使用姿势">使用姿势
&lt;/h2>&lt;h3 id="通过kubectl">通过kubectl
&lt;/h3>&lt;ul>
&lt;li>确保 Kubernetes 集群版本为 1.22 或更高，SSA 默认启用。&lt;/li>
&lt;li>使用 kubectl apply 应用配置时，注意可能出现的冲突，可以使用 &amp;ndash;force-conflicts 标志强制覆盖，但要谨慎。&lt;/li>
&lt;/ul>
&lt;h4 id="获取">获取
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">kubectl get configmap &lt;span class="nb">test&lt;/span> &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>  -o yaml &lt;span class="se">\
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="se">&lt;/span>  --show-managed-fields
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="更新">更新
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">kubectl apply -f config.yaml —server-side —field-manager&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>whoami&lt;span class="k">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h4 id="强制更新">强制更新
&lt;/h4>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">kubectl apply -f deployment.yaml --server-side —field-manager&lt;span class="o">=&lt;/span>&lt;span class="k">$(&lt;/span>whoami&lt;span class="k">)&lt;/span> --force-conflicts
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>处理冲突： SSA 会检测字段冲突，如果发生冲突，kubectl apply 会返回错误。
&lt;ul>
&lt;li>用户可以手动解决冲突，例如通过 kubectl edit 更新资源，或使用 &amp;ndash;force-conflicts 忽略冲突。&lt;/li>
&lt;li>建议定期检查资源的状态，确保没有意外覆盖。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>测试与验证： 在应用更改前，使用 &amp;ndash;dry-run=server 进行服务器端 dry run，验证更改是否会引发冲突。例如：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-shell" data-lang="shell">&lt;span class="line">&lt;span class="cl">kubectl apply -f deployment.yaml --dry-run&lt;span class="o">=&lt;/span>server -o yaml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="通过controller">通过controller
&lt;/h3>&lt;p>SSA 为控制器引入了一种新的 patch 类型，设置内容类型为 application/apply-patch+yaml 或 application/apply-patch+json 来应用 SSA。&lt;/p>
&lt;p>确保控制器只管理它负责的字段，避免与其他人或工具的更改冲突。处理冲突时，可以实现重试机制或提供解决冲突的逻辑，比如强制覆盖特定字段。&lt;/p>
&lt;ul>
&lt;li>k8s.io/client-go/applyconfigurations&lt;/li>
&lt;li>尽量使用 Client go applyconfigurations 提供的 Builder 模式来构建 patch， 而不是go struct来构建 apply patch，防止隐式的required字段的默认零值导致的意外修改&lt;/li>
&lt;li>k8s.io/code-generator&lt;/li>
&lt;li>applyconfiguration-gen&lt;/li>
&lt;li>使用 clientset的Apply()方法（code-gen —apply-configuration-package）&lt;/li>
&lt;/ul>
&lt;h2 id="总结">总结
&lt;/h2>&lt;p>SSA 特别适合多团队或多工具协作管理的场景。遵循最佳实践以最大化利用 SSA 的优势，减少冲突并提高资源管理的可靠性。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>项目&lt;/th>
&lt;th>详情&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>解决的问题&lt;/td>
&lt;td>多个客户端同时修改资源时的冲突，防止无意覆盖。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>版本支持&lt;/td>
&lt;td>从 1.22 版本开始 GA，默认启用，需确保集群版本 &amp;gt;= 1.22。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>实现方式&lt;/td>
&lt;td>API 服务器通过 managedFields 跟踪字段所有权，检测并处理冲突。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>kubectl 最佳实践&lt;/td>
&lt;td>确保集群支持 SSA，使用 kubectl apply，处理冲突，测试 dry run。&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>控制器最佳实践&lt;/td>
&lt;td>使用字段 Builder 模式，管理字段所有权，处理冲突，测试多管理器场景。&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="参考">参考
&lt;/h2>&lt;ul>
&lt;li>&lt;a class="link" href="https://kubernetes.io/zh-cn/docs/reference/using-api/server-side-apply/" target="_blank" rel="noopener"
>服务器端应用（Server-Side Apply） | Kubernetes&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=1rlTPjQ9dco" target="_blank" rel="noopener"
>Adopting Server Side Apply in Knative - a Case Study - Dave Protasowski, VMware&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.youtube.com/watch?v=oiC2w1PVjrQ" target="_blank" rel="noopener"
>SIG API Machinery Deep Dive - App&amp;hellip; Abu Kashem &amp;amp; Stefan Schimanski, Joe Betz &amp;amp; Federico Bongiovanni&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://pkg.go.dev/k8s.io/client-go/applyconfigurations" target="_blank" rel="noopener"
>applyconfigurations package - k8s.io/client-go/applyconfigurations - Go Packages&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://www.zeng.dev/post/2023-k8s-api-codegen/" target="_blank" rel="noopener"
>https://www.zeng.dev/post/2023-k8s-api-codegen/&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://blog.kagaya.fun/images/notbyai/en/Written-By-Human-Not-By-AI-Badge-white.png"
loading="lazy"
alt="notbyai-white"
>
&lt;img src="https://blog.kagaya.fun/images/notbyai/jp/Written-By-Human-Not-By-AI-Badge-black.png"
loading="lazy"
alt="notbyai-black"
>&lt;/p></description></item><item><title>使用Kubernetes V1.20.0 与 Containerd 配置K8s集群</title><link>https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/</link><pubDate>Thu, 17 Dec 2020 23:31:25 +0800</pubDate><guid>https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/</guid><description>&lt;img src="https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/k8s.png" alt="Featured image of post 使用Kubernetes V1.20.0 与 Containerd 配置K8s集群" />&lt;h1 id="使用kubernetes-v1200-与-containerd-配置k8s集群">使用Kubernetes V1.20.0 与 Containerd 配置K8s集群
&lt;/h1>&lt;h2 id="写在前面">写在前面
&lt;/h2>&lt;p>Kubernetes在最新的1.20.0版本中表示正式放弃了Docker，原来的Docker项目也早已改名为Moby了，即便Docker在容器技术中仍占据主流，并且在其他地方也能够继续发光发热，但从长远来看，容器运行时必然也会进入一个多方竞争的时代。对于适配了Kubernetes CRI的容器运行时，我们便有了很多选择，如Containerd和CRI-O。Docker目前占据了约七成的份额，而第二名Containerd也占据了两成多。刚好实验室有搭建集群的需求，作为爱折腾星人，决定紧跟时代，用最新的V1.20.0的Kubernetes与Containerd来搭建我们的实验集群。我会简单讲解我的配置过程以及中间遇到的问题及解决方法，毕竟自己踩过的坑，得讲一遍才能记得深刻（笑）&lt;/p>
&lt;p>本文所需shell脚本都在这个&lt;a class="link" href="https://github.com/kagaya85/K8sTakeOff" target="_blank" rel="noopener"
>repo&lt;/a>，如果之后有需要也会不断更新，对于配置过程中产生的问题欢迎在issue中讨论。&lt;/p>
&lt;h2 id="配置基本环境">配置基本环境
&lt;/h2>&lt;p>这次打算在四台裸机上部署一个单master节点，三个worker节点的小集群，单机配置如下：&lt;/p>
&lt;p>&lt;img src="https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-18_at_21.54.34@2x.png"
width="1658"
height="788"
srcset="https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-18_at_21.54.34@2x_hu_81a15d69d6a6f86e.png 480w, https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-18_at_21.54.34@2x_hu_e991947e35a2dd2c.png 1024w"
loading="lazy"
alt="CleanShot_2020-12-18_at_21.54.34@2x"
class="gallery-image"
data-flex-grow="210"
data-flex-basis="504px"
>&lt;/p>
&lt;p>当然这是我部署好后的截图，主机的名称也改为了ip+nodeType，方便识别当前主机，当然这也是必须修改的，因为原来的四台主机的主机名都为localhost.localdomain，同名主机在建立集群后不能一起显示，这也是配置时遇到的坑之一，所以我也同样将改名的命令分别写在了&lt;code>04_pull_master_images.sh&lt;/code>与&lt;code>04_pull_worker_images.sh&lt;/code>，可以自动实现将主机名替换为ip+nodeType，当然，这都是后话了。&lt;/p>
&lt;p>本次主要是在CentOS7下进行配置，要求能连接外网，对于kubernets需要的k8s.gcr.io上的镜像我也已经在阿里云上同步了一份，所以没有挂代理的要求。当然最好还是在root用户下执行，不保证非root用户的执行效果（可增加sudo尝试）&lt;/p>
&lt;p>对于每一台机器，只需要一次执行00～02对应脚本&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># cd进入脚本对应目录&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bash 00_install_tools.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bash 01_config_env.sh
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">bash 02_install_kube.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;ul>
&lt;li>
&lt;p>00安装了一些必要的工具，如git、vim、unzip、ntpdate等，安装了yum epel并对yum进行了换源。除此之外，还包含一些常用的工具如zsh、neofetch、htop等，同时也会将shell切换为zsh（⚠️注意，后文的脚本都是基于修改&lt;code>~/.zshrc&lt;/code>文件，如果不使用zsh，请对应修改为&lt;code>~/.bashrc&lt;/code>或&lt;code>~./bash_profile&lt;/code>），这里可以根据自己的需要做修改。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>01设置了一些基本环境配置，关闭firewalld和swap，设置了iptable转发等，特别是对时间进行同步，并修改为CST时区，保证各个主机上时间的一致性对集群的配置也至关重要。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>02为yum添加了Kubernetes的repo，安装了1.20.0版本的kubelet、kubeadm、kubectl三件套&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="安装containerd">安装Containerd
&lt;/h2>&lt;p>接下来，我们为每一台主机安装Containerd替换之前的Docker。&lt;/p>
&lt;p>一键安装：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 03_install_containerd.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Containerd的官方quick-start文档会默认你已经安装了runc（Containerd默认的容器运行工具），所以第一步我们还是要安装runc，否则将无法运行容器。&lt;/p>
&lt;p>我们直接选择拉取runc的官方仓库进行编译安装，runc比较小，编译很快，但是需要有go的运行环境和&lt;code>libseccomp&lt;/code> 、&lt;code>libseccomp-devel&lt;/code>两个链接库，可以参考&lt;a class="link" href="https://github.com/containerd/containerd/blob/master/BUILDING.md#build-runc" target="_blank" rel="noopener"
>这里&lt;/a>。这些都在脚本中安装好了，如果你不想编译，也可以下载编译好的二进制文件放到&lt;code>$PATH&lt;/code>对应的目录中即可。&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># install runc&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git clone https://github.com/opencontainers/runc
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nb">cd&lt;/span> runc &lt;span class="o">&amp;amp;&amp;amp;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> make &lt;span class="o">&amp;amp;&amp;amp;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> make install
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这样就安装好了runc工具&lt;/p>
&lt;p>安装Containerd也很简单，直接下载官方编译好的二进制压缩包，解压对应目录，这里我也选择了较新的1.4.3版本，甚至官方仓库的release tag里还是1.3.9版本&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CONTAINERD_VERSION&lt;/span>&lt;span class="o">=&lt;/span>1.4.3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">wget https://github.com/containerd/containerd/releases/download/v&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$CONTAINERD_VERSION&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>/containerd-&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$CONTAINERD_VERSION&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>-linux-amd64.tar.gz
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tar -xvf containerd-&lt;span class="s2">&amp;#34;&lt;/span>&lt;span class="nv">$CONTAINERD_VERSION&lt;/span>&lt;span class="s2">&amp;#34;&lt;/span>-linux-amd64.tar.gz -C /usr/local/
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>接下来就是比较关键也是我当时遇到问题最多的地方：containerd配置&lt;/p>
&lt;p>一般来说，containerd提供了生成默认配置的方法&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># 需提前创建对应目录 &lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># sudo mkdir -p /etc/containerd/&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">containerd config default &amp;gt;/etc/containerd/config.toml
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>但是这样会有&lt;strong>一些问题&lt;/strong>：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>之后在使用crictl工具连接containerd工具时会报错：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">unknown service runtime.v1alpha2.ImageService &amp;amp;Unimplemented desc = unknown service api.v1.CRIPluginService
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可参考这个&lt;a class="link" href="https://github.com/kubernetes-sigs/cri-tools/issues/436#issuecomment-464290289" target="_blank" rel="noopener"
>issue&lt;/a>，对应的解决方法就是修改以下配置&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-toml" data-lang="toml">&lt;span class="line">&lt;span class="cl">&lt;span class="p">[&lt;/span>&lt;span class="nx">plugins&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="s2">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nx">containerd&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">snapshotter&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;overlayfs&amp;#34;&lt;/span> &lt;span class="nx">--&lt;/span>&lt;span class="err">&amp;gt;&lt;/span> &lt;span class="s2">&amp;#34;native&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">default_runtime_name&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;runc&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">no_pivot&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>后面在使用&lt;code>kubeadm init&lt;/code>初始化集群时，在启动apiserver等pod时，会报错：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Unfortunately, an error has occurred:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> timed out waiting for the condition
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> This error is likely caused by:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - The kubelet is not running
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#39;systemctl status kubelet&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#39;journalctl -xeu kubelet&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Additionally, a control plane component may have crashed or exited when started by the container runtime.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> To troubleshoot, list all containers using your preferred container runtimes CLI.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Here is one example how you may list all Kubernetes containers running in cri-o/containerd using crictl:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#39;crictl --runtime-endpoint /run/containerd/containerd.sock ps -a | grep kube | grep -v pause&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Once you have found the failing container, you can inspect its logs with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#39;crictl --runtime-endpoint /run/containerd/containerd.sock logs CONTAINERID&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">couldn&amp;#39;t initialize a Kubernetes cluster
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>使用&lt;code>systemctl status kubelet&lt;/code>查看kubelet情况，可以看到kubelet有在运行但是日志里一直打印&lt;code>node &amp;quot;localhost.localdomain&amp;quot; not found&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-gdscript3" data-lang="gdscript3">&lt;span class="line">&lt;span class="cl">&lt;span class="err">●&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">service&lt;/span> &lt;span class="o">-&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">The&lt;/span> &lt;span class="n">Kubernetes&lt;/span> &lt;span class="ne">Node&lt;/span> &lt;span class="n">Agent&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Loaded&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">loaded&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">lib&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">systemd&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">system&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">service&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">enabled&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="n">vendor&lt;/span> &lt;span class="n">preset&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">disabled&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Drop&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">In&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="o">/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">lib&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">systemd&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">system&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">service&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">d&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="err">└─&lt;/span>&lt;span class="mi">10&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">kubeadm&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conf&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Active&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">active&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">running&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="n">since&lt;/span> &lt;span class="n">Thu&lt;/span> &lt;span class="mi">2020&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">12&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">48&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">18&lt;/span> &lt;span class="n">CST&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="mi">6&lt;/span>&lt;span class="nb">min&lt;/span> &lt;span class="n">ago&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Docs&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="n">https&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="o">//&lt;/span>&lt;span class="n">kubernetes&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">io&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">docs&lt;/span>&lt;span class="o">/&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Main&lt;/span> &lt;span class="n">PID&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Tasks&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mi">18&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">Memory&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="mf">37.6&lt;/span>&lt;span class="n">M&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">CGroup&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="o">/&lt;/span>&lt;span class="n">system&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">slice&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">service&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="err">└─&lt;/span>&lt;span class="mi">10688&lt;/span> &lt;span class="o">/&lt;/span>&lt;span class="n">usr&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bin&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubelet&lt;/span> &lt;span class="o">--&lt;/span>&lt;span class="n">bootstrap&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">kubeconfig&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">etc&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubernetes&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">bootstrap&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conf&lt;/span> &lt;span class="o">--&lt;/span>&lt;span class="n">kubeconfig&lt;/span>&lt;span class="o">=/&lt;/span>&lt;span class="n">etc&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubernetes&lt;/span>&lt;span class="o">/&lt;/span>&lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">conf&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.161585&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.261944&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.362297&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.462629&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.562916&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.663161&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.763546&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.863925&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">35&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">35.964162&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">Dec&lt;/span> &lt;span class="mi">17&lt;/span> &lt;span class="mi">20&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">36&lt;/span> &lt;span class="n">localhost&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">localdomain&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">10688&lt;/span>&lt;span class="p">]:&lt;/span> &lt;span class="n">E1217&lt;/span> &lt;span class="mi">07&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">54&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">36.064368&lt;/span> &lt;span class="mi">10688&lt;/span> &lt;span class="n">kubelet&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">go&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">2240&lt;/span>&lt;span class="p">]&lt;/span> &lt;span class="n">node&lt;/span> &lt;span class="s2">&amp;#34;localhost.localdomain&amp;#34;&lt;/span> &lt;span class="ow">not&lt;/span> &lt;span class="n">found&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里的日志不够详细，于是我又使用&lt;code>journalctl -xeu kubelet&lt;/code>查看更详细的日志，日志数量比较多，很容易漏掉关键的错误，比如说下面这条报错是我在重试了多次后才在日志中发现的：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CreatePodSandbox for pod &amp;#34;kube-scheduler-localhost.localdomain_kube-system(a28385ea64639c19ce25476016scheduler-localhost.localdomain_kube-system(a28385ea64639c19ce254760161b1d3b)&amp;#34; failed: rpc error: code = Unknown desc = failed to get sandboxb1d3b)&amp;#34; failed: rpc error: code = Unknown desc = failed to get sandbox image &amp;#34;k8s.gcr.io/pause:3.1&amp;#34;: failed to pull image &amp;#34;k8s.gcr.io/pause:3.1&amp;#34;: failed to pull image &amp;#34;k8s.gcr.io/pause:3.1&amp;#34;: failed to pull and unpack image &amp;#34;k8s.gcr.io/pause:3.1&amp;#34;:
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>可以看到中的关键信息&lt;code>failed to pull image &amp;quot;k8s.gcr.io/pause:3.1&amp;quot;&lt;/code>，也就是说kubelet创建pod时卡在了拉取pause镜像这一步，当时在初始化kubeadm之前，我已经在本地准备好了所有所需要的镜像，并且kubeadm通过指定镜像仓库的参数&lt;code>--image-repository=${IMAGE_REPOSITORY}&lt;/code>已经将kubelet所要拉取镜像的目标仓库切换为阿里云的仓库，但这里还是去从一个不存在的谷歌容器仓库k8s.gcr.io拉取镜像，导致我在这里一度怀疑是kubelet的配置问题。&lt;/p>
&lt;p>直到我翻到了kubeadm的&lt;a class="link" href="https://github.com/kubernetes/kubeadm/issues/2020" target="_blank" rel="noopener"
>issue#2020&lt;/a>中提到了kubeadm并不会配置pause image的repository，以及在containerd的&lt;a class="link" href="https://github.com/containerd/cri/issues/813" target="_blank" rel="noopener"
>issue#813&lt;/a>，提到了&lt;strong>pause镜像的仓库及版本是写在containerd的配置文件中&lt;/strong>，所以，只需要在&lt;code>config.toml&lt;/code>中修改以下配置&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-toml" data-lang="toml">&lt;span class="line">&lt;span class="cl">&lt;span class="p">[&lt;/span>&lt;span class="nx">plugins&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="s2">&amp;#34;io.containerd.grpc.v1.cri&amp;#34;&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">disable_tcp_service&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">true&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">stream_server_address&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;127.0.0.1&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">stream_server_port&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;0&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">stream_idle_timeout&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;4h0m0s&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">enable_selinux&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="kc">false&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nx">sandbox_image&lt;/span> &lt;span class="p">=&lt;/span> &lt;span class="s2">&amp;#34;k8s.gcr.io/pause:3.1&amp;#34;&lt;/span> &lt;span class="nx">--&lt;/span>&lt;span class="err">&amp;gt;&lt;/span> &lt;span class="s2">&amp;#34;registry.cn-hangzhou.aliyuncs.com/kagaya/pause:3.2&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>以上问题就解决了:-(&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>所以，配置脚本中直接生成了修改好的配置文件，使用脚本就不会遇到以上问题了&lt;/p>
&lt;h2 id="安装kubernetes并创建集群">安装Kubernetes并创建集群
&lt;/h2>&lt;p>以上的操作是需要在每一台主机进行配置，接下来的操作可能会有Master与Worker主机的区别，请注意。&lt;/p>
&lt;p>这里先使用上一步配置好的crictl工具拉取镜像为创建集群时节省时间&lt;/p>
&lt;ul>
&lt;li>
&lt;p>准备Master节点镜像&lt;/p>
&lt;p>执行以下脚本&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 04_pull_master_images.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>准备Worker节点镜像&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 04_pull_worker_images.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;/li>
&lt;li>
&lt;p>以上两步会以ip+nodeType的格式同时修改Master和Worker节点的主机名，原因写在了文章开头&lt;/p>
&lt;/li>
&lt;li>
&lt;p>初始化Master节点&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 05_init_master.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这一步会在kubeadm中指定kubernetes的版本，CIDR范围，镜像仓库等，如果顺利的话，你可以看到最后打印的其他节点join集群的方法，类似这样：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">kubeadm join 192.168.0.170:6443 --token r7w69v.3e1nweyk81h5zj6y \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> --discovery-token-ca-cert-hash sha256:1234a2317d27f0a4c6bcf5f284416a2fb3e8f3bd61aa88bc279a4f6ef18e09a1
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>之后需要手动在&lt;strong>各个Worker节点&lt;/strong>上执行一下这条命令加入Master所在集群，请务必确保各节点时间同步，因为token的合法性会用时间去验证。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>如果需要，你还可以使用&lt;code>05_init_worker_kubectl.sh&lt;/code>来初始化Worker节点上的kubectl命令&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>如果以上步骤顺利的话，你现在可以在Master节点上使用&lt;code>kubectl get nodes -o wide&lt;/code>看到各个节点的信息，当然Status为NotReady是因为我们还没有执行最后一步，安装calico网络&lt;/p>
&lt;p>&lt;img src="https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-17_at_22.41.02@2x.png"
width="2844"
height="486"
srcset="https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-17_at_22.41.02@2x_hu_72fdedff15b2bd9b.png 480w, https://blog.kagaya.fun/p/2020/%E4%BD%BF%E7%94%A8kubernetes-v1.20.0-%E4%B8%8E-containerd-%E9%85%8D%E7%BD%AEk8s%E9%9B%86%E7%BE%A4/CleanShot_2020-12-17_at_22.41.02@2x_hu_b9d3886a47fef3f4.png 1024w"
loading="lazy"
alt="CleanShot_2020-12-17_at_22.41.02@2x"
class="gallery-image"
data-flex-grow="585"
data-flex-basis="1404px"
>&lt;/p>
&lt;h2 id="安装calico网络">安装Calico网络
&lt;/h2>&lt;p>这一步就比较简单了，只需要在每个Node上都从Dockerhub上拉取对应的镜像，然后从&lt;strong>Master节点&lt;/strong>上用kubectl应用yaml文件。&lt;/p>
&lt;p>一键脚本：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 06_install_calico.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>这里也选用了较新的Calico v3.17.1&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CALICO_VERSION&lt;/span>&lt;span class="o">=&lt;/span>v3.17.1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">crictl pull calico/cni:&lt;span class="nv">$CALICO_VERSION&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">crictl pull calico/pod2daemon-flexvol:&lt;span class="nv">$CALICO_VERSION&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">crictl pull calico/node:&lt;span class="nv">$CALICO_VERSION&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">crictl pull calico/kube-controllers:&lt;span class="nv">$CALICO_VERSION&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>默认的yaml文件来自官方的3.17版本，我也在manifests目录下准备了离线版本&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">CALICO_YAML&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;https://docs.projectcalico.org/v3.17/manifests/calico.yaml&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># CALICO_YAML=&amp;#34;./manifests/calico.yaml&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>kubernetes会在各个节点上使用DaemonSet的方式运行calico pod，这样各个节点的pod就可以通过虚拟网络进行通信了。&lt;/p>
&lt;h2 id="最后说几句">最后说几句
&lt;/h2>&lt;p>以上就基本完成了K8s集群的搭建，如果需要，还可以安装metrics server以提供各个节点的Cpu与Mem资源信息&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">bash 07_install_metrics_server.sh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>当然，文中所提到的问题并不是全部，其他诸如安装metric server时的错误：&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">metric-server : TLS handshake error from 20.99.219.64:57467: EOF
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>需要通过修改metric server deployment的启动参数解决&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-yaml" data-lang="yaml">&lt;span class="line">&lt;span class="cl">- &lt;span class="nt">args&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- --&lt;span class="l">kubelet-insecure-tls&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>- --&lt;span class="l">kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>如果有其他问题，也欢迎在&lt;a class="link" href="https://github.com/kagaya85/K8sTakeOff/issues" target="_blank" rel="noopener"
>这里&lt;/a>提交issue交流。&lt;/p>
&lt;p>最后：&lt;/p>
&lt;p>&lt;strong>Kill Docker And Long Live Kubernetes!!!&lt;/strong>&lt;/p></description></item></channel></rss>